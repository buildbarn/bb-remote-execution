syntax = "proto3";

package buildbarn.configuration.bb_scheduler;

import "build/bazel/remote/execution/v2/remote_execution.proto";
import "google/protobuf/duration.proto";
import "pkg/proto/configuration/blobstore/blobstore.proto";
import "pkg/proto/configuration/cloud/aws/aws.proto";
import "pkg/proto/configuration/global/global.proto";
import "pkg/proto/configuration/grpc/grpc.proto";

option go_package = "github.com/buildbarn/bb-remote-execution/pkg/proto/configuration/bb_scheduler";

message ApplicationConfiguration {
  // Address on which to listen to expose the web UI.
  //
  // TODO: This web UI no longer needs to be integrated into
  // bb_scheduler, as the underlying information can be exposed over
  // gRPC using the 'build_queue_state_grpc_servers' option.
  string admin_http_listen_address = 2;

  // gRPC servers to spawn to listen for requests from clients
  // (bb_storage or Bazel).
  repeated buildbarn.configuration.grpc.ServerConfiguration
      client_grpc_servers = 3;

  // gRPC servers to spawn to listen for requests from bb_worker.
  repeated buildbarn.configuration.grpc.ServerConfiguration
      worker_grpc_servers = 4;

  // URL of the Buildbarn Browser, linked to by the web UI.
  string browser_url = 5;

  // Configuration for blob storage.
  buildbarn.configuration.blobstore.BlobAccessConfiguration
      content_addressable_storage = 6;

  // Maximum Protobuf message size to unmarshal.
  int64 maximum_message_size_bytes = 7;

  // Common configuration options that apply to all Buildbarn binaries.
  buildbarn.configuration.global.Configuration global = 8;

  // AWS Auto Scaling Group lifecycle hooks that should be used to
  // automatically drain EC2 instances that are about to be terminated,
  // and to delay their termination until all operations running on
  // those systems have completed.
  //
  // More details:
  // https://docs.aws.amazon.com/autoscaling/ec2/userguide/lifecycle-hooks.html
  //
  // TODO: This feature no longer needs to be integrated into
  // bb_scheduler, as workers can be terminated over gRPC using the
  // 'build_queue_state_grpc_servers' option.
  repeated AWSASGLifecycleHookConfiguration aws_asg_lifecycle_hooks = 9;

  // AWS access options and credentials.
  buildbarn.configuration.cloud.aws.SessionConfiguration aws_session = 10;

  // gRPC servers to spawn to expose the state of the build queue. This
  // can be used to obtain access to the data shown in the web UI in a
  // programmatic manner.
  repeated buildbarn.configuration.grpc.ServerConfiguration
      build_queue_state_grpc_servers = 11;

  // Create platform queues that are always present, regardless of
  // whether there are workers synchronizing against the scheduler.
  //
  // It is required to use this option to create platform queues that
  // support multiple worker size classes.
  repeated PredeclaredPlatformQueueConfiguration predeclared_platform_queues =
      12;

  // Execution timeout that needs to be applied in case the build action
  // contains no explicit timeout.
  google.protobuf.Duration default_execution_timeout = 13;

  // Maximum permitted execution timeout.
  google.protobuf.Duration maximum_execution_timeout = 14;
}

message AWSASGLifecycleHookConfiguration {
  // The URL of the Simple Queue Service (SQS) queue where
  // "autoscaling:EC2_INSTANCE_TERMINATING" events are posted.
  string sqs_url = 1;

  // Label that should be used to match the instance ID of the EC2
  // instance (i-*) against workers known by the scheduler. For example,
  // if your workers are all called {"instance": "i-*", "thread": "*"},
  // then this configuration option should be set to "instance".
  //
  // On systems like Amazon EKS, it is possible to attach an instance ID
  // label to workers by creating an initContainer that stores the
  // contents of http://169.254.169.254/latest/meta-data/instance-id in
  // a file in an emptyDir. This file can then be loaded by bb_worker on
  // startup using Jsonnet's importstr command.
  //
  // Setting this configuration option incorrectly may cause the
  // scheduler to not drain the right set of workers.
  string instance_id_label = 2;
}

message PredeclaredPlatformQueueConfiguration {
  // The instance name prefix of the platform queue to create.
  string instance_name_prefix = 1;

  // The platform properties of the platform queue to create.
  build.bazel.remote.execution.v2.Platform platform = 2;

  // The maximum size class for which workers exist for this platform
  // queue. All actions that fail on smaller size classes will be
  // retried on workers of this size class.
  uint32 maximum_size_class = 3;

  // When not set, run all actions on the smallest size class for which
  // workers exist. Upon failure, retry actions on the largest size
  // class. This mode is not recommended for setups with more than two
  // size classes, or workloads where build times matter.
  //
  // When set, run all actions on the largest size class if not seen
  // before. Future invocations of actions with the same command line
  // arguments and environment variables will run on all size classes,
  // using probabilities based on how their execution times compare to
  // those of the largest size class.
  //
  // Statistics on execution times are persisted into the Initial Size
  // Class Cache (ISCC). bb_browser is also capable of reading data from
  // this data store, making it possible to view these statistics by
  // visiting the page of an action.
  InitialSizeClassFeedbackDrivenAnalyzerConfiguration
      initial_size_class_feedback_driven_analyzer = 4;

  // Allow workers to continue to execute actions from the same
  // invocation, if doing so keeps the number of workers assigned to an
  // invocation balanced, and the difference in age between the first
  // queued operation remains below the configured limit. It is worth
  // setting this option if there is an inherent overhead when switching
  // between actions belonging to different invocations.
  //
  // For example, consider the case where workers are configured to run
  // tests inside virtual machines, and that the virtual machine's boot
  // image is provided as part of the input root. When actions that use
  // the same boot image run right after each other, the existing
  // virtual machine may be repurposed. If the boot image is different,
  // a costly restart needs to be performed. By adding stickiness, the
  // probability of needing to do virtual machine restarts decreases.
  //
  // This option may require a custom implementation of
  // InvocationIDExtractor to be effective.
  //
  // Recommended value: 0s
  google.protobuf.Duration worker_invocation_stickiness_limit = 5;
}

message InitialSizeClassFeedbackDrivenAnalyzerConfiguration {
  // The Initial Size Class Cache (ISCC) where execution times of
  // actions are read and written.
  buildbarn.configuration.blobstore.BlobAccessConfiguration
      initial_size_class_cache = 1;

  // Immediately schedule actions on the largest size class if they have
  // failed at least once within the provided timeframe.
  //
  // Actions that fail on any size class other than the largest will
  // always be retried on the largest size class to rule out failures
  // caused by a lack of resources. This means that if an action is
  // known to fail, attempting to run it on smaller size classes causes
  // unnecessary delays in error reporting.
  //
  // During iterative development, it is likely that the same action
  // action is invoked repeatedly, each time having a high probability
  // of failure. This option controls how long these kinds of actions
  // should receive a boost, allowing them to be run on the largest size
  // class and fail quickly.
  //
  // Recommended value: 86400s (1 day)
  google.protobuf.Duration failure_cache_duration = 2;

  // An exponent to determine whether an increase in execution time when
  // scheduling an action on a smaller size class is considere
  // acceptable.
  //
  // For example, consider the case where this exponent is set to 0.7,
  // and a given action is known to have a 60s median execution time on
  // the largest workers, having size class 16. For the execution time
  // to be considered being acceptable on a smaller size class, this
  // action must complete within:
  //
  // - 60s*(16/1)^0.7 = 417.8s on a worker with size class 1,
  // - 60s*(16/2)^0.7 = 257.2s on a worker with size class 2,
  // - 60s*(16/4)^0.7 = 158.3s on a worker with size class 4,
  // - 60s*(16/8)^0.7 =  97.7s on a worker with size class 8.
  //
  // Whereas if this exponent is set to 0.3, the acceptable execution
  // times would be significantly lower:
  //
  // - 60s*(16/1)^0.3 = 137.8s on a worker with size class 1,
  // - 60s*(16/2)^0.3 = 112.0s on a worker with size class 2,
  // - 60s*(16/4)^0.3 =  90.9s on a worker with size class 4,
  // - 60s*(16/8)^0.3 =  73.9s on a worker with size class 8.
  //
  // In effect, this exponent determines how much speed you are willing
  // to sacrifice for increased worker utilization. Setting this
  // exponent to a higher value will increase worker utilization, but
  // may cause actions that are only somewhat parallel to run slower.
  //
  // Recommended value: somewhere between 0.2 and 0.8.
  double acceptable_execution_time_increase_exponent = 3;

  // Actions scheduled on smaller size classes are run with a reduced
  // timeout value that is based on the acceptable execution time of the
  // action for that size class (see above). This ensures that if a
  // misprediction is made and an action is running unacceptably slow on
  // a size class that is too small, it is terminated and quickly
  // retried on the largest size class.
  //
  // This option configures a multiplier that needs to be applied when
  // computing the action's timeout. Setting it to >1.0 gives an action
  // a bit more time to finish its work, even if its execution time has
  // become unacceptable. This has two advantages:
  //
  // - Less work is wasted, as the action may likely still complete.
  // - If we still observe a timeout on the smaller size class, we
  //   insert a higher quality data point into the ISCC.
  //
  // Recommended value: 1.5
  double smaller_size_class_execution_timeout_multiplier = 4;

  // The execution timeout value that is used on smaller size classes is
  // proportional to the median execution time observed on the largest
  // size class. This means that if the median execution time on the
  // largest size class is in the milliseconds, so will be the execution
  // timeout on smaller size classes.
  //
  // Because this tends to introduce too much flakiness, this option can
  // be used to set an lower bound on the execution timeout.
  //
  // Recommended value: 10s
  google.protobuf.Duration minimum_execution_timeout = 5;

  // This implementation compares previous execution stats between every
  // pair of size classes. The resulting scores are stored in a
  // stochastic matrix, of which the resulting eigenvector contains the
  // probabilities at which size classes should be chosen. This
  // algorithm has a strong resemblance with PageRank.
  //
  // To compute the eigenvector, a process called "power iteration" is
  // used, in which repeated matrix multiplications are performed. This
  // method approximates the eigenvector, each iteration giving more
  // accurate results. This option can be used to control how many
  // iterations should be performed. Matrix multiplication will be
  // terminated as soon as the maximum observed error drops below a
  // certain value.
  //
  // It is generally possible to set this option to an aggressive (low)
  // value, for a couple of reasons:
  //
  // - The number of size classes tends to be small (<10), meaning that
  //   the resulting probability matrix is also not too big (<10x10).
  // - The probability function used to populate the stochastic matrix
  //   is total and asymmetric, meaning that every iteration strongly
  //   contributes to convergence.
  // - Probabilities of previous executions of the same action are
  //   cached in the Initial Size Class Cache (ISCC), meaning that
  //   the algorithm often has a good starting point.
  //
  // Still, it is recommended to inspect Prometheus metrics
  // buildbarn_builder_page_rank_strategy_calculator_* in case changes
  // are made to this option to assess the performance impact.
  //
  // Recommended value: 0.002
  double maximum_convergence_error = 6;

  // The number of action outcomes to store per size class. Increasing
  // this improves the accuracy of timing information that is captured,
  // but has the downside that the system responds to changes in
  // behavior of actions less quickly.
  //
  // To ensure that the system does not end up in a steady state where
  // actions are always run on the same size class, there is roughly a
  // 1.0 / history_size probability that actions are run on sizes
  // classes other than the optimum, regardless of historical outcomes.
  //
  // Recommended value: 32
  int32 history_size = 7;

  // There is a small probability that this implementation runs actions
  // on size classes even if it is fairly certain that they are
  // suboptimal (either too small or too large). This is necessary, as
  // without it there is a chance that previous execution statistics
  // stored in the ISCC remain permanently outdated. The downside of
  // this strategy is that it may cause unnecessary delays, especially
  // when attempted against long-running actions that are part of the
  // critical path of a build.
  //
  // To mitigate this, this implementation uses an alternative execution
  // strategy in case there is a >50% probability of failure on a
  // smaller size class. Instead of first executing the action on the
  // smaller size class, followed by falling back to the largest size
  // class, it schedules it the other way around. The client is
  // unblocked as soon as the execution on the largest size class
  // succeeds, while the execution on the smallest size class is
  // performed in the background.
  //
  // To make sure that operations that are merely created to perform
  // learning in the background don't starve other builds that are
  // taking place, all of them are placed in a single fictive
  // invocation, so that fairness is respected.
  //
  // This option determines the maximum number of background learning
  // operations that may be in the QUEUED execution stage, per size
  // class. Excessive operations are discarded. Not only is it necessary
  // to set this value to ensure that the scheduler doesn't run out of
  // memory due to background actions piling up, it can also put a limit
  // on how much the cluster is scaled up (in case autoscaling based on
  // queue sizes is performed).
  //
  // Recommended value: 1000
  int32 maximum_queued_background_learning_operations = 8;

  // The REv2 execution priority that needs to be used for background
  // learning operations.
  //
  // bb_scheduler respects REv2 execution priorities by increasing the
  // number of actions to run concurrently between invocations by a
  // factor 2 for every 100 decrease in priority value (i.e., lower
  // priority value means faster builds).
  //
  // This option determines how aggressively background learning
  // operations should be preferred over operations enqueued by clients.
  //
  // Recommended value: 0
  int32 background_learning_operation_priority = 9;
}
